# {{.ServiceName}} Configuration - gRPC + GraphQL Service

service:
  name: "{{.ServiceName}}"
  version: "1.0.0"
  grpc_port: 9090
  graphql_port: 8080
  environment: "development"

# Core configurations using existing libraries
config:
  providers:
    file:
      path: "./configs"
      format: "yaml"
    env:
      prefix: "{{.ServiceName | upper}}_"
    consul:
      address: "${CONSUL_ADDRESS}"
      token: "${CONSUL_TOKEN}"

logging:
  providers:
    console:
      level: "info"
      format: "json"
    file:
      path: "/var/log/{{.ServiceName}}.log"
      level: "debug"
      max_size: 100
      max_backups: 3
      max_age: 28
    elasticsearch:
      endpoint: "${ELASTICSEARCH_ENDPOINT}"
      index: "{{.ServiceName}}-logs"

monitoring:
  providers:
    prometheus:
      endpoint: "${PROMETHEUS_ENDPOINT}"
      port: 9090
    jaeger:
      endpoint: "${JAEGER_ENDPOINT}"
      service_name: "{{.ServiceName}}"
    grafana:
      endpoint: "${GRAFANA_ENDPOINT}"

database:
  providers:
    postgresql:
      url: "${DATABASE_URL}"
      max_connections: 100
      max_idle_connections: 10
      connection_max_lifetime: "1h"
    redis:
      url: "${REDIS_URL}"
      db: 0
      pool_size: 10

auth:
  providers:
    jwt:
      secret: "${JWT_SECRET}"
      expiration: "24h"
      issuer: "{{.ServiceName}}"
    oauth:
      client_id: "${OAUTH_CLIENT_ID}"
      client_secret: "${OAUTH_CLIENT_SECRET}"
      redirect_url: "${OAUTH_REDIRECT_URL}"
      scopes: ["read", "write"]

middleware:
  auth:
    enabled: true
    provider: "jwt"
  rate_limit:
    enabled: true
    requests_per_minute: 100
    burst: 10
  circuit_breaker:
    enabled: true
    failure_threshold: 5
    timeout: 30s
    max_requests: 3

# Communication configuration using existing libraries
communication:
  providers:
    grpc:
      host: "0.0.0.0"
      port: 9090
      max_recv_msg_size: 4194304  # 4MB
      max_send_msg_size: 4194304  # 4MB
      enable_reflection: true
      timeout: 30s
      keepalive:
        time: 30s
        timeout: 5s
        permit_without_stream: true
      compression:
        enabled: true
        algorithm: "gzip"
      tls:
        enabled: false
        cert_file: "${TLS_CERT_FILE}"
        key_file: "${TLS_KEY_FILE}"
      interceptors:
        - "auth"
        - "logging"
        - "monitoring"
        - "rate_limit"
        - "circuit_breaker"
    graphql:
      host: "0.0.0.0"
      port: 8080
      read_timeout: 30s
      write_timeout: 30s
      idle_timeout: 120s
      max_request_size: 1048576  # 1MB
      enable_introspection: true
      enable_playground: true
      playground_path: "/playground"
      graphql_path: "/graphql"
      cors:
        enabled: true
        origins: ["*"]
        methods: ["GET", "POST", "OPTIONS"]
        headers: ["Content-Type", "Authorization"]
      compression:
        enabled: true
        algorithm: "gzip"
      tls:
        enabled: false
        cert_file: "${TLS_CERT_FILE}"
        key_file: "${TLS_KEY_FILE}"
      middleware:
        - "auth"
        - "logging"
        - "monitoring"
        - "rate_limit"
        - "circuit_breaker"
      schema:
        path: "./graphql/{{.ServiceName}}.graphql"
        auto_reload: true
        validation:
          enabled: true
          max_depth: 10
          max_complexity: 1000

# Optional configurations using existing libraries
{{#if .WithAI}}
ai:
  providers:
    openai:
      api_key: "${OPENAI_API_KEY}"
      default_model: "gpt-4"
      timeout: 30s
    anthropic:
      api_key: "${ANTHROPIC_API_KEY}"
      default_model: "claude-3-sonnet"
      timeout: 30s
{{/if}}

{{#if .WithStorage}}
storage:
  providers:
    s3:
      access_key: "${AWS_ACCESS_KEY_ID}"
      secret_key: "${AWS_SECRET_ACCESS_KEY}"
      region: "${AWS_REGION}"
      bucket: "${S3_BUCKET}"
    gcs:
      credentials_file: "${GCS_CREDENTIALS_FILE}"
      bucket: "${GCS_BUCKET}"
{{/if}}

{{#if .WithMessaging}}
messaging:
  providers:
    kafka:
      brokers: "${KAFKA_BROKERS}"
      group_id: "{{.ServiceName}}"
      topics: ["{{.ServiceName}}-events", "{{.ServiceName}}-commands"]
    rabbitmq:
      url: "${RABBITMQ_URL}"
      exchange: "{{.ServiceName}}-exchange"
      queue: "{{.ServiceName}}-queue"
{{/if}}

{{#if .WithScheduling}}
scheduling:
  providers:
    cron:
      timezone: "UTC"
    redis:
      url: "${REDIS_URL}"
      db: 1
{{/if}}

{{#if .WithBackup}}
backup:
  providers:
    s3:
      bucket: "${BACKUP_S3_BUCKET}"
      region: "${BACKUP_S3_REGION}"
    gcs:
      bucket: "${BACKUP_GCS_BUCKET}"
{{/if}}

{{#if .WithChaos}}
chaos:
  providers:
    chaos_monkey:
      enabled: false
      failure_rate: 0.1
      latency: "100ms"
{{/if}}

{{#if .WithFailover}}
failover:
  providers:
    consul:
      address: "${CONSUL_ADDRESS}"
      service_name: "{{.ServiceName}}"
      health_check_interval: "10s"
{{/if}}

{{#if .WithEvent}}
event:
  providers:
    postgresql:
      url: "${EVENT_POSTGRES_URL}"
      table: "events"
    kafka:
      brokers: "${EVENT_KAFKA_BROKERS}"
      topic: "events"
{{/if}}

{{#if .WithDiscovery}}
discovery:
  providers:
    consul:
      address: "${CONSUL_ADDRESS}"
      token: "${CONSUL_TOKEN}"
    kubernetes:
      config_path: "${KUBERNETES_CONFIG}"
{{/if}}

{{#if .WithCache}}
cache:
  providers:
    redis:
      url: "${CACHE_REDIS_URL}"
      db: 2
      ttl: "1h"
    memory:
      max_size: 1000
      ttl: "30m"
{{/if}}

{{#if .WithRateLimit}}
ratelimit:
  providers:
    redis:
      url: "${RATELIMIT_REDIS_URL}"
      db: 3
    memory:
      requests_per_minute: 100
{{/if}}

{{#if .WithCircuitBreaker}}
circuitbreaker:
  providers:
    memory:
      failure_threshold: 5
      timeout: 30s
      max_requests: 3
{{/if}}
